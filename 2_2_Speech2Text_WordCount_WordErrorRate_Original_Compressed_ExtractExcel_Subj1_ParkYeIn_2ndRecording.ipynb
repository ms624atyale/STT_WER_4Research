{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1MxpJxwnqUX0jiSpv/dHG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ms624atyale/CL4Research/blob/main/2_2_Speech2Text_WordCount_WordErrorRate_Original_Compressed_ExtractExcel_Subj1_ParkYeIn_2ndRecording.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this modified code, the convert_speech_to_text() function remains the same as before, which converts speech to text using Google STT. The count_words() function also remains the same, which counts the number of words in the text.\n",
        "\n",
        "The code iterates over the WAV files in the specified folder. For each WAV file, it converts the speech to text using convert_speech_to_text(), then counts the number of words in the converted text using count_words(). Finally, it prints the filename, converted text, and word count for each WAV file.\n",
        "\n",
        "Make sure to adjust the folder_path variable to the actual path of your WAV files. After making these adjustments, run the code, and it will apply Google STT on each WAV file, retrieve the converted text, and count the number of words in the text for each WAV file."
      ],
      "metadata": {
        "id": "qQVtTYE72IgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ 1. <font color = 'blue'>Tokenization, Cleaning & Normalization</font> (subj1, rep1, all text, original)**\n",
        "  - Full Text: North Wind and the Sun were disputing which was the stronger, when a traveler came along wrapped in a warm cloak. They agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other. Then the North Wind blew as hard as he could, but the more he blew the more closely did the traveler fold his cloak around him; and at last the North Wind gave up the attempt. Then the Sun shined out warmly, and immediately the traveler took off his cloak. And so the North Wind was obliged to confess that the Sun was the stronger of the two.\n",
        "  \n",
        " - #reference12: small letters across the board without punctuations\n",
        "\n",
        " - #hypothesis9: same as original text with punctuations\n",
        " - #hypothesis10: small letters across the board with punctuations\n",
        " - #hypothesis11: small letters across the board without punctuations\n",
        " - #hypothesis12: small letters across the board without punctuations"
      ],
      "metadata": {
        "id": "jKK1eYa1ZIRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis_texts = [\"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the traveler from his club around him and i lost the nursery and immediately go traveling was only\",\n",
        "                    \"the nursery and the sun world is putting which was stronger when i travel i came along work in a warm club they are really that the one who forced to succeed in making the traveler take his clock of should be considered stronger than the other in the nurse main blue as hard as he could put them away he blew the more closely did the traveler for his club around him and i lost the nursery nursery\",\n",
        "                    \"the nurse win and the song world is putting which was stronger when a traveler came around worked in the alarm clock they are really that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other then the nurse wind blew as hard as he could but\",\n",
        "                    \"the nurse wind and the sun world is putting this was the stronger when a traveler came along with the warm clock they are read that the one who first succeeded in making the traveler take his clock off should be considered a stronger than the other than the north wind blow us hard as he could put the more he blew the more closely did the traveler for his clock around him and unless the north wind gave up the tent in the song in the sky shine on me and immediately was alive to confess that the sun was the stronger of\",\n",
        "                    \"the nurse win and the song where they speak english with the stronger when the traveler came or not in the room clock they agreed that the one who first succeed in making the traveler take his clock off should be considered stronger than the other than the north wind blew as hard as he could put the more he blew the more closely did the turbo for his club around him and i left the list the nursery was over to confess that the song was the stronger of the two\",\n",
        "                    \"the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock they agreed that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could the more he blew the more closely together for his clock around him and i left the nursery was obviously to confess that the song was the stronger of the two\",\n",
        "                    \"the nurse win and the sun was disputing which was the stronger when a traveler came along route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and i left and there's one game of the attempt in the sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\",\n",
        "                    \"the nurse win and the sun was disputing which was the stronger when a traveler came along route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and i left and there's one game of the attempt in the sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\",\n",
        "                    \"the north wind and the sun were disputing which was the stronger, when a traveler came along wrapped in a warm cloak. they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other. then the north wind blew as hard as he could, but the more he blew the more closely did the traveler fold his cloak around him; and at last the north wind gave up the attempt. then the sun shined out warmly, and immediately the traveler took off his cloak. and so the north wind was obliged to confess that the sun was the stronger of the two.\",\n",
        "                    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "kO2-b7M_9YlS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "import string\n",
        "\n",
        "reference_text = \"The North Wind and the Sun were disputing which was the stronger, when a traveler came along wrapped in a warm cloak. They agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other. Then the North Wind blew as hard as he could, but the more he blew the more closely did the traveler fold his cloak around him; and at last the North Wind gave up the attempt. Then the Sun shined out warmly, and immediately the traveler took off his cloak. And so the North Wind was obliged to confess that the Sun was the stronger of the two.\"\n",
        "convert2small_reference = reference_text.lower()\n",
        "\n",
        "# Remove punctuation marks\n",
        "translator = str.maketrans(\"\", \"\", string.punctuation)\n",
        "cleaned_reference = convert2small_reference.translate(translator)\n",
        "\n",
        "# Tokenize the cleaned reference text\n",
        "token_prefinal = text_to_word_sequence(cleaned_reference)\n",
        "sent_convert = ' '.join(token_prefinal)\n",
        "print('Tokenizing Words after Cleaning Punctuations: %s' % sent_convert)"
      ],
      "metadata": {
        "id": "bLdsx7qf8urZ",
        "outputId": "1d1a370b-bd32-4c37-e278-6ea58af4040e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing Words after Cleaning Punctuations: the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üêπ <font color = 'brown'> google STT (SpeechRecognition package) applied to a list of oritinal wav. files and their corresponding word count** ‚§µÔ∏è\n",
        "\n",
        "###**üåµ 1. STT (subj1, rep1, all text, original)**"
      ],
      "metadata": {
        "id": "fXvHSq8o74HD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "    lowercase_text = text.lower()  # Convert the text to lowercase\n",
        "\n",
        "    return lowercase_text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_session2_para_original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "teUoaGzw2s7V",
        "outputId": "630e49db-484b-4f1c-e0a1-4616daec1ae3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n",
            "File: subj1_session2_para6.wav\n",
            "Text: the north wind and the song where this good thing which was the stronger when i travel i came along work in a warm clothes they are with the dead the one who first to succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse in the pool as hard as he could but the more he blew the more closely to travel or for his club around him and unless there's one gave up the attempt in the sun in the sky shine out of me and immediately was always the stronger of the two\n",
            "Word Count: 105\n",
            "\n",
            "File: subj1_session2_para8.wav\n",
            "Text: the north wind and the sun world is putting which was the stronger when the traveler came around where you know one club they are with that the one who first succeed in making the traveler take his clothes off to be considered stronger than the other than the north wind will you asked as he could but the more people the more closely to travel report his club around him and unless the nurse when gave up the attempt in the sun in the sky shine down lonely and immediately to travel to get his clothes and so the nursery\n",
            "Word Count: 101\n",
            "\n",
            "File: subj1_session2_para5.wav\n",
            "Text: the nursery and the sunrise is putting which was the stronger when the traveler came along work in a warm club they are already dead the one who first succeeded in making the traveler take his club up should be considered stronger than the other and the nurse when the blue as hard as he could put the more he blew the more closely did the trailer for his club around him and unless the nurse in the game of the attempt then the sun in the sky shine on me and immediately to travel to nursery\n",
            "Word Count: 97\n",
            "\n",
            "File: subj1_session2_para3.wav\n",
            "Text: the north wind in the somewhere just putting which was the stronger when the traveler came or not work in a long clock they are with that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse went to his heart as he could put the more he blew the more closely the trouble for the clock around him and the last the nursery and immediately to travel to the north main was obligated to confess that the song was the stronger of the two\n",
            "Word Count: 98\n",
            "\n",
            "File: subj1_session2_para1.wav\n",
            "Text: the north wind and the song where is the thing which is the stronger when the traveling alone work in a warm clock they are always dead the one who first succeeded in making the traveler take his clothes off should be considered a stronger than the other in the north wind blew as hard as he could well the more he believed the more closely to travel for 6:00 around him and unless the nursery and immediately the trailer\n",
            "Word Count: 80\n",
            "\n",
            "File: subj1_session2_para2.wav\n",
            "Text: the nursery in the sunrise is putting which was stronger when a traveler came along work in a warm clothes they are with that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other than the north wind blew as hard as he could but the more he believed the more closely the trailer for his clothes around him and ask the nurse when gave up the attempt the sun in the sky shine not only and immediately when was obligated to confess that the song was the stronger of the two\n",
            "Word Count: 102\n",
            "\n",
            "File: subj1_session2_para4.wav\n",
            "Text: the nurse wind and the sun world is putting which was the stronger than the traveler came along work in a warm clothes they agreed that the one who first succeeded in making the travelers take his clock up should be considered stronger than the other in the north wind blew as hard as he could put the more he blew the more closely to travel for his club around him and unless the north wind gave up the temp in the sun is in the sky shine on me and the immediately the traveling with the song was the stronger of the two\n",
            "Word Count: 104\n",
            "\n",
            "File: subj1_session2_para7.wav\n",
            "Text: the nurse wind and the sun world is putting which was the stronger when i travel came along work in a warm clothes they are with that the one who first succeeded in making the trouble i take his clothes off should be considered a stronger than the other in the north wind blew as hard as he could put the more he blew the more closely the trailer for his car or on him and asked the nurse in the game of the attempt then the sign in the sky shine down on me and immediately the song in the sky shine out of me and immediately to travel and soda north wayne was always did confess that the song was the stronger of the two\n",
            "Word Count: 127\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original Full Text of 'The North Wind and the Sun' abbreviated as OFT\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install Levenshtein\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak they agreed that the one who first succeeded in making the traveler take his cloak off should be considered stronger than the other then the north wind blew as hard as he could but the more he blew the more closely did the traveler fold his cloak around him and at last the north wind gave up the attempt then the sun shined out warmly and immediately the traveler took off his cloak and so the north wind was obliged to confess that the sun was the stronger of the two\"\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\"the north wind and the song where is the thing which is the stronger when the traveling alone work in a warm clock they are always dead the one who first succeeded in making the traveler take his clothes off should be considered a stronger than the other in the north wind blew as hard as he could well the more he believed the more closely to travel for 6:00 around him and unless the nursery and immediately the trailer\",\n",
        "                    \"the nursery in the sunrise is putting which was stronger when a traveler came along work in a warm clothes they are with that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other than the north wind blew as hard as he could but the more he believed the more closely the trailer for his clothes around him and ask the nurse when gave up the attempt the sun in the sky shine not only and immediately when was obligated to confess that the song was the stronger of the two\",\n",
        "                    \"the north wind in the somewhere just putting which was the stronger when the traveler came or not work in a long clock they are with that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse went to his heart as he could put the more he blew the more closely the trouble for the clock around him and the last the nursery and immediately to travel to the north main was obligated to confess that the song was the stronger of the two\",\n",
        "                    \"the nurse wind and the sun world is putting which was the stronger than the traveler came along work in a warm clothes they agreed that the one who first succeeded in making the travelers take his clock up should be considered stronger than the other in the north wind blew as hard as he could put the more he blew the more closely to travel for his club around him and unless the north wind gave up the temp in the sun is in the sky shine on me and the immediately the traveling with the song was the stronger of the two\",\n",
        "                    \"the nursery and the sunrise is putting which was the stronger when the traveler came along work in a warm club they are already dead the one who first succeeded in making the traveler take his club up should be considered stronger than the other and the nurse when the blue as hard as he could put the more he blew the more closely did the trailer for his club around him and unless the nurse in the game of the attempt then the sun in the sky shine on me and immediately to travel to nursery\",\n",
        "                    \"the north wind and the song where this good thing which was the stronger when i travel i came along work in a warm clothes they are with the dead the one who first to succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse in the pool as hard as he could but the more he blew the more closely to travel or for his club around him and unless there's one gave up the attempt in the sun in the sky shine out of me and immediately was always the stronger of the two\",\n",
        "                    \"the nurse wind and the sun world is putting which was the stronger when i travel came along work in a warm clothes they are with that the one who first succeeded in making the trouble i take his clothes off should be considered a stronger than the other in the north wind blew as hard as he could put the more he blew the more closely the trailer for his car or on him and asked the nurse in the game of the attempt then the sign in the sky shine down on me and immediately the song in the sky shine out of me and immediately to travel and soda north wayne was always did confess that the song was the stronger of the two\",\n",
        "                    \"the north wind and the sun world is putting which was the stronger when the traveler came around where you know one club they are with that the one who first succeed in making the traveler take his clothes off to be considered stronger than the other than the north wind will you asked as he could but the more people the more closely to travel report his club around him and unless the nurse when gave up the attempt in the sun in the sky shine down lonely and immediately to travel to get his clothes and so the nursery\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = [\"Full Text of 'The Nor {}\".format(i+1) for i in range(len(wer_values))]\n",
        "\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_fulltext_sess2.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "id": "Mg470zPla7-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12506211-4798-4c0e-eae2-6442cd3633f6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: Levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein) (3.1.1)\n",
            "                          WER\n",
            "Full Text of 'The Nor 1  0.56\n",
            "Full Text of 'The Nor 2  0.35\n",
            "Full Text of 'The Nor 3  0.43\n",
            "Full Text of 'The Nor 4  0.36\n",
            "Full Text of 'The Nor 5  0.49\n",
            "Full Text of 'The Nor 6  0.47\n",
            "Full Text of 'The Nor 7  0.48\n",
            "Full Text of 'The Nor 8  0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  3. STT (subj1, rep1, sentence1, original)**"
      ],
      "metadata": {
        "id": "TGzZW3DS8aw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "    lowercase_text = text.lower()  # Convert the text to lowercase\n",
        "\n",
        "    return lowercase_text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_session2_sent1_original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bxfabYsAEwk",
        "outputId": "06bceb5d-fe12-40db-bfaf-07686e6fca0b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: sent7.wav\n",
            "Text: the nurse wind and the sun world is putting which was the stronger when a traveler came along work in a warm\n",
            "Word Count: 22\n",
            "\n",
            "File: sent3.wav\n",
            "Text: the north wind in the somewhere just putting which was the stronger when the traveler came or not worked in a long clock\n",
            "Word Count: 23\n",
            "\n",
            "File: sent8.wav\n",
            "Text: the north wind and the sun world is putting which was the stronger when the traveler came around work in a warm\n",
            "Word Count: 22\n",
            "\n",
            "File: sent5.wav\n",
            "Text: the nursery and the sunrise is putting which was the stronger when the traveler came along work in a war\n",
            "Word Count: 20\n",
            "\n",
            "File: sent2.wav\n",
            "Text: the nursery in the sunrise is putting which was stronger when a traveler came along work in a warm clothes\n",
            "Word Count: 20\n",
            "\n",
            "File: sent1.wav\n",
            "Text: the north wind and the song where is the thing which was the stronger when the traveling alone work in a warm clothes\n",
            "Word Count: 23\n",
            "\n",
            "File: sent6.wav\n",
            "Text: the north wind and the song where this good thing which was the stronger when i travel i came along work in a warm\n",
            "Word Count: 24\n",
            "\n",
            "File: sent4.wav\n",
            "Text: the nurse wind and the sun world is putting which was the stronger than the traveler came along work in a war\n",
            "Word Count: 22\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  4 WER (subj1, rep1, sentence1, original)**"
      ],
      "metadata": {
        "id": "-vauZFNEZVDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "    \"the north wind and the sun were disputing which was the stronger when a traveler came along wrapped in a warm cloak \",\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\"the north wind and the song where is the thing which was the stronger when the traveling alone work in a warm clothes\",\n",
        "                    \"the nursery in the sunrise is putting which was stronger when a traveler came along work in a warm clothes\",\n",
        "                    \"the north wind in the somewhere just putting which was the stronger when the traveler came or not worked in a long clock\",\n",
        "                    \"the nurse wind and the sun world is putting which was the stronger than the traveler came along work in a war\",\n",
        "                    \"the nursery and the sunrise is putting which was the stronger when the traveler came along work in a war\",\n",
        "                    \"the north wind and the song where this good thing which was the stronger when i travel i came along work in a warm\",\n",
        "                    \"the nurse wind and the sun world is putting which was the stronger when a traveler came along work in a warm\",\n",
        "                    \"the north wind and the sun world is putting which was the stronger when the traveler came around work in a warm\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = [\"Sentence1 of 'the North Wind and the Sun'{}\".format(i+1) for i in range(len(wer_values))]\n",
        "\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_sent1_sess2.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "id": "dfaro8QIaB0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d656e0-99da-4a6c-b209-c168252e2a3c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             WER\n",
            "Sentence1 of 'the North Wind and the Sun'1  0.50\n",
            "Sentence1 of 'the North Wind and the Sun'2  0.41\n",
            "Sentence1 of 'the North Wind and the Sun'3  0.45\n",
            "Sentence1 of 'the North Wind and the Sun'4  0.41\n",
            "Sentence1 of 'the North Wind and the Sun'5  0.41\n",
            "Sentence1 of 'the North Wind and the Sun'6  0.45\n",
            "Sentence1 of 'the North Wind and the Sun'7  0.27\n",
            "Sentence1 of 'the North Wind and the Sun'8  0.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  5. STT (subj1, rep1, main clause, original)**\n",
        "###üê• **original sentence divided into main clause**"
      ],
      "metadata": {
        "id": "wBChSHExcWf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "    lowercase_text = text.lower()  # Convert the text to lowercase\n",
        "\n",
        "    return lowercase_text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_session2_main_origianl\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "4YCPK_9YcdkQ",
        "outputId": "e1f55c5d-578d-4a42-f8a3-7759ef4455c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: main7.wav\n",
            "Text: the nurse wind and the sun world is putting which was the strong\n",
            "Word Count: 13\n",
            "\n",
            "File: main8.wav\n",
            "Text: the north wind and the sun world is putting which was the\n",
            "Word Count: 12\n",
            "\n",
            "File: main1.wav\n",
            "Text: the north wind and the song where is the thing which was the\n",
            "Word Count: 13\n",
            "\n",
            "File: main2.wav\n",
            "Text: the nursery in the sunrise is putting which was strong\n",
            "Word Count: 10\n",
            "\n",
            "File: main6.wav\n",
            "Text: the north wind and the song where this good thing which was the stronger\n",
            "Word Count: 14\n",
            "\n",
            "File: main3.wav\n",
            "Text: the north wind and the somewhere this putting which was the strong\n",
            "Word Count: 12\n",
            "\n",
            "File: main5.wav\n",
            "Text: the nursery and the sunrise is putting which was the\n",
            "Word Count: 10\n",
            "\n",
            "File: main4.wav\n",
            "Text: the north wind and the sun world is putting which was the stronger\n",
            "Word Count: 13\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  6. WER (subj1, rep1, main clause, original)**\n",
        "  - üÜò Alert: In this code, I've imported the numpy library as np and used the reshape function to convert originalsentence1 into a 2D array with dimensions (8, 1). This ensures that the shape of the values matches the implied shape based on the indices and columns specified for the DataFrame.\n",
        "\n",
        "  No longer relevent, but I need to work on array using numpy."
      ],
      "metadata": {
        "id": "WLdGxED_aGs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\",\n",
        "    \"the north wind and the sun were disputing which was the stronger\"\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\n",
        "    \"the north wind and the song where is the thing which was the\",\n",
        "    \"the nursery in the sunrise is putting which was strong\",\n",
        "    \"the north wind and the somewhere this putting which was the strong\",\n",
        "    \"the north wind and the sun world is putting which was the stronger\",\n",
        "    \"the nursery and the sunrise is putting which was the\",\n",
        "    \"the north wind and the song where this good thing which was the stronger\",\n",
        "    \"the nurse wind and the sun world is putting which was the strong\",\n",
        "    \"the north wind and the sun world is putting which was the\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = ['Main Clause of Sentence1{}'.format(i+1) for i in range(len(wer_values))]\n",
        "\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_mainclause_sess2.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQtLSJV-9y8u",
        "outputId": "c90d39f2-5ae6-4c58-c31d-d7dffa225a11"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            WER\n",
            "Main Clause of Sentence11  0.50\n",
            "Main Clause of Sentence12  0.67\n",
            "Main Clause of Sentence13  0.33\n",
            "Main Clause of Sentence14  0.25\n",
            "Main Clause of Sentence15  0.50\n",
            "Main Clause of Sentence16  0.42\n",
            "Main Clause of Sentence17  0.42\n",
            "Main Clause of Sentence18  0.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  7. STT (subj1, rep1, subordinate clause, original)**\n",
        "###üê• **original sentence divided into subordinate clause**"
      ],
      "metadata": {
        "id": "aRdTVoFIdrN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "    lowercase_text = text.lower()  # Convert the text to lowercase\n",
        "\n",
        "    return lowercase_text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_session2_sub_original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "qqWhaWHfdoqd",
        "outputId": "00323648-b6b9-4a70-d6b1-e2b946c33d13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: sub2.wav\n",
            "Text: when a traveler came along work in a warm clothes\n",
            "Word Count: 10\n",
            "\n",
            "File: sub4.wav\n",
            "Text: when the traveler came along work in a war\n",
            "Word Count: 9\n",
            "\n",
            "File: sub7.wav\n",
            "Text: when a trailer came along work in a warm\n",
            "Word Count: 9\n",
            "\n",
            "File: sub5.wav\n",
            "Text: in a war\n",
            "Word Count: 3\n",
            "\n",
            "File: sub3.wav\n",
            "Text: when it's regular game or not we're up in a alarm clock\n",
            "Word Count: 12\n",
            "\n",
            "File: sub6.wav\n",
            "Text: when i travel i came along work in a warm\n",
            "Word Count: 10\n",
            "\n",
            "File: sub8.wav\n",
            "Text: when a traveler came around work in a warm\n",
            "Word Count: 9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üÜò <font color = 'red'> ParkYeIn_paragraph1_sent1_sub1 ÎïåÎ¨∏Ïóê chatGPT ÌÜµÌï¥ÏÑú  except sr.UnknownValueError: ÏΩîÎìúÎùºÏù∏ÏùÑ ÏÇΩÏûÖÌïòÏó¨ Î¨∏Ï†ú ÌïµÍ≤∞Ìï®!"
      ],
      "metadata": {
        "id": "MC7kEl83VzC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "        lowercase_text = text.lower()  # Convert the text to lowercase\n",
        "    except sr.UnknownValueError:\n",
        "        lowercase_text = \"Unable to transcribe speech.\"\n",
        "\n",
        "    return lowercase_text\n",
        "\n",
        "#def convert_speech_to_text(audio_file):\n",
        "    #recognizer = sr.Recognizer()\n",
        "\n",
        "    #with sr.AudioFile(audio_file) as source:\n",
        "        #audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    #text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "    #lowercase_text = text.lower()  # Convert the text to lowercase\n",
        "\n",
        "    #return lowercase_text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_session2_sub_original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "5pMaShbkR9_U",
        "outputId": "c8afe978-3bdd-4771-8d56-583bef13f2a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: sub2.wav\n",
            "Text: when a traveler came along work in a warm clothes\n",
            "Word Count: 10\n",
            "\n",
            "File: sub4.wav\n",
            "Text: when the traveler came along work in a war\n",
            "Word Count: 9\n",
            "\n",
            "File: sub7.wav\n",
            "Text: when a trailer came along work in a warm\n",
            "Word Count: 9\n",
            "\n",
            "File: sub1.wav\n",
            "Text: Unable to transcribe speech.\n",
            "Word Count: 4\n",
            "\n",
            "File: sub5.wav\n",
            "Text: in a war\n",
            "Word Count: 3\n",
            "\n",
            "File: sub3.wav\n",
            "Text: when it's regular game or not we're up in a alarm clock\n",
            "Word Count: 12\n",
            "\n",
            "File: sub6.wav\n",
            "Text: when i travel i came along work in a warm\n",
            "Word Count: 10\n",
            "\n",
            "File: sub1_redo_deletefinalnoise.wav\n",
            "Text: in a war\n",
            "Word Count: 3\n",
            "\n",
            "File: sub8.wav\n",
            "Text: when a traveler came around work in a warm\n",
            "Word Count: 9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  8. WER (subj1, rep1, subordinate clause, original)**"
      ],
      "metadata": {
        "id": "pj5h1HY9aQnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts. Caution to be taken: sub1 ÌîºÏùºÏùÄ ÏóêÎü¨Í∞Ä ÎÇòÏÑú Ìè¨Ìï® ÏïàÏãúÌÇ¥ (Unable to transcribe speech.)\n",
        "reference_texts = [\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\",\n",
        "    \"when a traveler came along wrapped in a warm cloak\"\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\n",
        "    \"in a war\",\n",
        "    \"when a traveler came along work in a warm clothes\",\n",
        "    \"when it's regular game or not we're up in a alarm cloc\",\n",
        "    \"when the traveler came along work in a war\",\n",
        "    \"in a war\",\n",
        "    \"when i travel i came along work in a warm\",\n",
        "    \"when a trailer came along work in a warm\",\n",
        "    \"when a traveler came around work in a warm\",\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = ['Subordinate Clause of Sentence1{}'.format(i+1) for i in range(len(wer_values))]\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_subordinateclause_sess2.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "id": "So1kD9T1Kms9",
        "outputId": "2f8a449b-37bb-47ce-8748-c6653de4a00c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  WER\n",
            "Subordinate Clause of Sentence11  0.8\n",
            "Subordinate Clause of Sentence12  0.2\n",
            "Subordinate Clause of Sentence13  0.9\n",
            "Subordinate Clause of Sentence14  0.4\n",
            "Subordinate Clause of Sentence15  0.8\n",
            "Subordinate Clause of Sentence16  0.5\n",
            "Subordinate Clause of Sentence17  0.3\n",
            "Subordinate Clause of Sentence18  0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ  9. STT (subj1, rep1, last 4 words, original)**"
      ],
      "metadata": {
        "id": "mIwCsbE4aT6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "    lowercase_text = text.lower()  # Convert the text to lowercase\n",
        "\n",
        "    return lowercase_text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"/content/sample_data/subj1_session2_last4words_original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "xEMlSDv_jh87",
        "outputId": "06093379-5277-4108-f297-f3305b85ff3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "File: last4words7.wav\n",
            "Text: in a war\n",
            "Word Count: 3\n",
            "\n",
            "File: last4words4.wav\n",
            "Text: in a\n",
            "Word Count: 2\n",
            "\n",
            "File: last4words1.wav\n",
            "Text: in a warm\n",
            "Word Count: 3\n",
            "\n",
            "File: last4words5.wav\n",
            "Text: in a war\n",
            "Word Count: 3\n",
            "\n",
            "File: last4words6.wav\n",
            "Text: in a war\n",
            "Word Count: 3\n",
            "\n",
            "File: last4words2.wav\n",
            "Text: in a warm\n",
            "Word Count: 3\n",
            "\n",
            "File: last4words8.wav\n",
            "Text: you know one\n",
            "Word Count: 3\n",
            "\n",
            "File: last4words3.wav\n",
            "Text: an alarm clock\n",
            "Word Count: 3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üåµ 10. WER (subj1, rep1, last 4 words, original)**"
      ],
      "metadata": {
        "id": "MTOM2frKaaED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\n",
        "    \"in a warm\",\n",
        "    \"in a warm\",\n",
        "    \"an alarm clock\",\n",
        "    \"in a\",\n",
        "    \"in a war\",\n",
        "    \"in a war\",\n",
        "    \"in a war\",\n",
        "    \"you know one\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = ['Subordinate Clause of Sentence1{}'.format(i+1) for i in range(len(wer_values))]\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_last4words_sess2.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "id": "ngwyegGUG17_",
        "outputId": "f9926a2d-d0bf-4bc2-8a5b-38ced546edf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   WER\n",
            "Subordinate Clause of Sentence11  0.25\n",
            "Subordinate Clause of Sentence12  0.25\n",
            "Subordinate Clause of Sentence13  1.00\n",
            "Subordinate Clause of Sentence14  0.50\n",
            "Subordinate Clause of Sentence15  0.50\n",
            "Subordinate Clause of Sentence16  0.50\n",
            "Subordinate Clause of Sentence17  0.50\n",
            "Subordinate Clause of Sentence18  1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**üêπ <font color = 'brown'> Noise cancellation and compression applied** ‚§µÔ∏è"
      ],
      "metadata": {
        "id": "20Agm7Dj7dJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üêπ <font color = 'green'> google STT (SpeechRecognition package) applied to a list of compressed wav. files and their corresponding word count** ‚§µÔ∏è"
      ],
      "metadata": {
        "id": "bNexgs_58cLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **1. Transform original (rep1_sentence1) to denoised and compressed wav. format**"
      ],
      "metadata": {
        "id": "sruS4_UOUSKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# subj1_rep1_sentence1_original to denoised and comprsssed format\n",
        "\n",
        "!pip install librosa\n",
        "!pip install pydub\n",
        "!pip install numpy\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pydub.effects import compress_dynamic_range\n",
        "\n",
        "def reduce_noise(audio_file, threshold=0.02):\n",
        "    y, sr = librosa.load(audio_file)\n",
        "\n",
        "    # Compute the short-term power of the audio\n",
        "    power = np.abs(librosa.stft(y))**2\n",
        "\n",
        "    # Set values below the threshold to zero\n",
        "    mask = power < threshold * np.max(power)\n",
        "    power[mask] = 0\n",
        "\n",
        "    # Reconstruct the audio\n",
        "    y_clean = librosa.istft(np.sqrt(power) * np.exp(1j * np.angle(librosa.stft(y))))\n",
        "\n",
        "    return y_clean, sr\n",
        "\n",
        "def compress_audio(audio_file, threshold=-20.0, ratio=4.0):\n",
        "    audio = AudioSegment.from_file(audio_file)\n",
        "\n",
        "    # Apply dynamic range compression\n",
        "    compressed_audio = compress_dynamic_range(audio, threshold=threshold, ratio=ratio)\n",
        "\n",
        "    return compressed_audio, audio.frame_rate\n",
        "\n",
        "# Path to the folder containing the sound files\n",
        "folder_path = \"/content/sample_data/subj1_session2_para_original\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Apply noise reduction\n",
        "        denoised_audio, sr = reduce_noise(audio_file, threshold=0.02)\n",
        "\n",
        "        # Apply dynamic range compression\n",
        "        compressed_audio, sr = compress_audio(audio_file, threshold=-20.0, ratio=4.0)\n",
        "\n",
        "        # Save the denoised audio to a new file\n",
        "        denoised_filename = \"denoised_\" + filename\n",
        "        sf.write(denoised_filename, denoised_audio, sr)\n",
        "\n",
        "        # Save the compressed audio to a new file\n",
        "        compressed_filename = \"compressed_\" + filename\n",
        "        compressed_audio.export(compressed_filename, format=\"wav\")\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Denoised audio saved as: {denoised_filename}\")\n",
        "        print(f\"Compressed audio saved as: {compressed_filename}\\n\")"
      ],
      "metadata": {
        "id": "UVvvO0wJAofb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**üêô 2. STT (subj1, rep1, all text, compressed)**"
      ],
      "metadata": {
        "id": "kRaYMInjYMsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"PATH\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")\n"
      ],
      "metadata": {
        "id": "IvW9ttq68bWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **3. WER (subj1, rep1, all text, compressed)**"
      ],
      "metadata": {
        "id": "XvldsYzJYg5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = ['Subordinate Clause of Sentence1{}'.format(i+1) for i in range(len(wer_values))]\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_para_compressed.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "id": "LO-oSOm7Dao4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **4. STT (subject1, rep1, sent1, compressed)**"
      ],
      "metadata": {
        "id": "S3dAP_qMU1ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subject1_sentence1_compressed\n",
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"PATH\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "K0WCBGRGC7Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **5. WER (subject1, rep1, sent1, compressed)**"
      ],
      "metadata": {
        "id": "L3nU8_fBVGxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = ['Subordinate Clause of Sentence1{}'.format(i+1) for i in range(len(wer_values))]\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_sent1_compressed.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "id": "I1tes04NDiWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **6. STT (subject1, rep1, main clause, compressed)**\n",
        "###üê• **compressed sentence divided into main clause**"
      ],
      "metadata": {
        "id": "_7_fg4iOfNKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"PATH\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "VJ5boQTRfP4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **7. WER (subject1, rep1, main clause, compressed)**"
      ],
      "metadata": {
        "id": "YLYxi0CkVYMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = ['Subordinate Clause of Sentence1{}'.format(i+1) for i in range(len(wer_values))]\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_main_compressed.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "id": "nbgV2PkuDriT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **8. STT (subject1, rep1, subordinate clause, compressed)**\n",
        "###üê• **compressed sentence divided into subordinate clause**"
      ],
      "metadata": {
        "id": "uzhbakt0fPcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"PATH\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "PKaDfU0ifOPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **9. WER (subject1, rep1, subordinate clause, compressed)**"
      ],
      "metadata": {
        "id": "LdqCHcSjVpTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = ['Subordinate Clause of Sentence1{}'.format(i+1) for i in range(len(wer_values))]\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_subordinate_compressed.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "id": "8nzfcySpDyHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **10. STT (subject1, rep1, last 4 words, compressed)**"
      ],
      "metadata": {
        "id": "AEwn4VHDWAGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#last 4 words (compressed)\n",
        "\n",
        "!pip install SpeechRecognition\n",
        "\n",
        "import os\n",
        "import speech_recognition as sr\n",
        "\n",
        "def convert_speech_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)  # Load the audio file\n",
        "\n",
        "    text = recognizer.recognize_google(audio)  # Use Google Speech Recognition API\n",
        "\n",
        "    return text\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "# Path to the folder containing the WAV files\n",
        "folder_path = \"PATH\"\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_file = os.path.join(folder_path, filename)\n",
        "\n",
        "        converted_text = convert_speech_to_text(audio_file)  # Convert speech to text\n",
        "\n",
        "        word_count = count_words(converted_text)  # Count the words in the converted text\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Text: {converted_text}\")\n",
        "        print(f\"Word Count: {word_count}\\n\")"
      ],
      "metadata": {
        "id": "ASE3Eyt6jaT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üêô **11. WER(subject1, rep1, last 4 words, compressed)**"
      ],
      "metadata": {
        "id": "NUU8aY4yWMlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import Levenshtein\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    reference_words = reference.split()\n",
        "    hypothesis_words = hypothesis.split()\n",
        "\n",
        "    # Compute Levenshtein distance between the reference and hypothesis\n",
        "    distance = Levenshtein.distance(reference_words, hypothesis_words)\n",
        "\n",
        "    # Calculate Word Error Rate (WER)\n",
        "    wer = distance / len(reference_words)\n",
        "    return round(wer, 2)  # Round the WER to two decimal places. >>return wer ÎùºÍ≥† code line Ïì∞Î©¥, longer decimal places for default\n",
        "\n",
        "# Calculate WER for each pair of texts\n",
        "reference_texts = [\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "    \"in a warm cloak\",\n",
        "]\n",
        "\n",
        "hypothesis_texts = [\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"\"\n",
        "]\n",
        "\n",
        "wer_values = []\n",
        "for reference, hypothesis in zip(reference_texts, hypothesis_texts):\n",
        "    wer = calculate_wer(reference, hypothesis)\n",
        "    wer_values.append(wer)\n",
        "\n",
        "# Create a DataFrame from the WER values\n",
        "df = pd.DataFrame(np.array(wer_values).reshape(-1, 1), columns=['WER'])\n",
        "df.index = ['Subordinate Clause of Sentence1{}'.format(i+1) for i in range(len(wer_values))]\n",
        "print(df)\n",
        "\n",
        "output_file = 'subj1_last4words_compressed.xlsx'\n",
        "df.to_excel(output_file, index=False)"
      ],
      "metadata": {
        "id": "a_79Rt97D27N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚ùé**Ignore below!**\n",
        "\n",
        "Word Error Rate\n",
        "\n",
        "Use small letters"
      ],
      "metadata": {
        "id": "GlUCzpTnGgsC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZU4a35-Gvns",
        "outputId": "472ad12d-8803-4e7a-af16-b5897ade0852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 10, 'nurse': 2, 'wind': 2, 'and': 3, 'sun': 1, 'world': 1, 'is': 1, 'building': 1, 'which': 1, 'was': 2, 'stronger': 2, 'when': 1, 'a': 2, 'traveler': 2, 'came': 1, 'along': 1, 'work': 1, 'in': 2, 'warm': 1, 'clock': 2, 'they': 1, 'are': 1, 'reset': 1, 'one': 1, 'who': 1, 'first': 1, 'succeeded': 1, 'making': 1, 'take': 1, 'his': 2, 'of': 1, 'should': 1, 'be': 1, 'considered': 1, 'than': 2, 'other': 1, 'blew': 2, 'as': 2, 'hard': 1, 'he': 2, 'could': 1, 'but': 1, 'more': 2, 'closely': 1, 'The': 1, 'Traveler': 1, 'from': 1, 'Club': 1, 'around': 1, 'him': 1, 'I': 1, 'lost': 1, 'nursery': 1, 'immediately': 1, 'go': 1, 'traveling': 1, 'only': 1}\n"
          ]
        }
      ],
      "source": [
        "def word_count(text):\n",
        "    # Split the text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Create a dictionary to store word counts\n",
        "    word_counts = {}\n",
        "\n",
        "    # Count the occurrences of each word\n",
        "    for word in words:\n",
        "        if word in word_counts:\n",
        "            word_counts[word] += 1\n",
        "        else:\n",
        "            word_counts[word] = 1\n",
        "\n",
        "    return word_counts\n",
        "\n",
        "\n",
        "subj1_rep1_ori = \"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely The Traveler from his Club around him and I lost the nursery and immediately go traveling was only\"\n",
        "counts = word_count(subj1_rep1_ori)\n",
        "print(counts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words(text):\n",
        "    words = text.split()  # Split the text into words\n",
        "    return len(words)    # Return the count of words\n",
        "\n",
        "\n",
        "subj1_rep1_ori = \"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely The Traveler from his Club around him and I lost the nursery and immediately go traveling was only\"\n",
        "wc1 = count_words(subj1_rep1_ori)\n",
        "print(wc1)\n",
        "\n",
        "subj1_rep1_compress = \"the nurse wind and the sun world is building which was the stronger when a traveler came along work in a warm clock they are reset the one who first succeeded in making the traveler take his clock of should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the\"\n",
        "wc1_1 = count_words(subj1_rep1_compress)\n",
        "print(wc1_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep2_ori = \"the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm Club they are really that the one who forced to succeed in making the traveler take his clock of should be considered stronger than the other in the nurse main blue as hard as he could put them away he blew the more closely did The Traveler for his Club around him and I lost the nursery nursery\"\n",
        "wc2 = count_words(subj1_rep2_ori)\n",
        "print(wc2)\n",
        "\n",
        "subj1_rep2_compress = \"the nursery and the sun world is putting which was Stronger when I travel I came along work in a warm Club they are really that the one who forced to succeed in making the traveler take his clock of should be considered stronger than the other in the nurse main blue as hard as he could put them away he blew the more closely did The Traveler for his Club around him and I lost the nursery nursery\"\n",
        "wc2_1 = count_words(subj1_rep2_compress)\n",
        "print(wc2_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep3_ori = \"the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock they are really that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other then the nurse wind blew as hard as he could but\"\n",
        "wc3 = count_words(subj1_rep3_ori)\n",
        "print(wc3)\n",
        "\n",
        "subj1_rep3_compress = \"the nurse win and the song world is putting which was Stronger when a traveler came around worked in the alarm clock they are really that the one who first succeed in making the traveler take his clothes off should be considered stronger than the other then the nurse wind blew as hard as he could but\"\n",
        "wc3_1 = count_words(subj1_rep3_compress)\n",
        "print(wc3_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep4_ori = \"the nurse wind and the sun world is putting this was the stronger when a traveler came along with the warm clock they are read that the one who first succeeded in making the traveler take his clock off should be considered a stronger than the other than the north wind blow us hard as he could put the more he blew the more closely did The Traveler for his clock around him and unless the north wind gave up the tent in the song in the sky shine on me and immediately was alive to confess that the sun was the stronger of\"\n",
        "wc4 = count_words(subj1_rep4_ori)\n",
        "print(wc4)\n",
        "\n",
        "subj1_rep4_compress = \"the nurse wind and the sun world is putting this was the stronger when a traveler came out of work in the warm clock they are read that\"\n",
        "wc4_1 = count_words(subj1_rep4_compress)\n",
        "print(wc4_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep5_ori = \"the nurse win and the song where they speak English with the stronger when the traveler came or not in the room clock they agreed that the one who first succeed in making the traveler take his clock off should be considered stronger than the other than the north wind blew as hard as he could put the more\"\n",
        "wc5 = count_words(subj1_rep5_ori)\n",
        "print(wc5)\n",
        "\n",
        "subj1_rep5_compress = \"the nurse win and the song where they speak English with the stronger when the traveler came or not in the room clock they agreed that the one who first succeed in making the traveler take his clock off should be considered stronger than the other than the north wind blew as hard as he could put the more he blew the more closely did the turbo for his Club around him and I left the list the nursery\"\n",
        "wc5_1 = count_words(subj1_rep5_compress)\n",
        "print(wc5_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep6_ori = \"the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock they agreed that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could the more he blew the more closely together for his clock around him and I left the nursery was obviously to confess that the song was the stronger of the two\"\n",
        "wc6 = count_words(subj1_rep6_ori)\n",
        "print(wc6)\n",
        "\n",
        "subj1_rep6_compress = \"the nurse mean and the song world is putting which was the stronger when a traveler came along rough in a warm clock they agreed that the one who first succeeded in\"\n",
        "wc6_1 = count_words(subj1_rep6_compress)\n",
        "print(wc6_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep7_ori = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\"\n",
        "wc7 = count_words(subj1_rep7_ori)\n",
        "print(wc7)\n",
        "\n",
        "subj1_rep7_compress = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and\"\n",
        "wc7_1 = count_words(subj1_rep7_compress)\n",
        "print(wc7_1)\n",
        "print('\\n')\n",
        "\n",
        "subj1_rep8_ori = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the more closely the doctor for his clock around him and I left and there's one game of the attempt in the Sun in the sky shine at warmly and immediately to travel to the nurse when was over to confess that the sun was the stronger of the two\"\n",
        "wc8 = count_words(subj1_rep8_ori)\n",
        "print(wc8)\n",
        "\n",
        "subj1_rep8_compress = \"the nurse win and the sun was disputing which was the stronger when a traveler came along Route in the warm clothes they are great that the one who first succeeded in making the traveler take his clothes off should be considered stronger than the other than the nurse wind blew as hard as he could but the more he blew the\"\n",
        "wc8_1 = count_words(subj1_rep8_compress)\n",
        "print(wc8_1)\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfxUl393Js2S",
        "outputId": "808c059b-0b1f-4bf5-ba16-dd684853a51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82\n",
            "62\n",
            "\n",
            "\n",
            "79\n",
            "79\n",
            "\n",
            "\n",
            "57\n",
            "57\n",
            "\n",
            "\n",
            "104\n",
            "28\n",
            "\n",
            "\n",
            "59\n",
            "79\n",
            "\n",
            "\n",
            "87\n",
            "32\n",
            "\n",
            "\n",
            "111\n",
            "91\n",
            "\n",
            "\n",
            "111\n",
            "62\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}